{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(\"../data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"length\"] = df[\"session_mask\"].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "df = [elem for elem in df.groupby('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "def concatenate(vectors):\n",
    "    elements = [elem for elem in vectors]\n",
    "    return np.concatenate(elements, axis=None)\n",
    "\n",
    "def append_dataframe(df):\n",
    "    id = df[0]\n",
    "    df = df[1]\n",
    "    \n",
    "    df = df.sort_values(\"timestamp\")\n",
    "    history = concatenate(df[\"history\"].values)\n",
    "    timestamp = concatenate(df[\"timestamp\"].values)\n",
    "    session = concatenate(df[\"session\"].values)\n",
    "    session_mask = concatenate(df[\"session_mask\"].values)\n",
    "    user_mask = concatenate(df[\"user_mask\"].values)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"id\": [id],\n",
    "        \"history\": [history],\n",
    "        \"timestamp\": [timestamp],\n",
    "        \"session\": [session],\n",
    "        \"session_mask\": [session_mask],\n",
    "        \"user_mask\": [user_mask],\n",
    "        \"length\": np.sum(df[\"length\"].values)\n",
    "    })\n",
    "\n",
    "with multiprocessing.Pool(cores) as p:\n",
    "    df = list(tqdm(p.imap(append_dataframe, df), total=len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/masked.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(\"../data/brunch/session.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"../data/dictionary.json\") as fp:\n",
    "    dictionary = json.load(fp)\n",
    "    \n",
    "def make_label(x):\n",
    "    session = x[\"history\"]\n",
    "    session = [dictionary[elem] for elem in session if elem in dictionary]\n",
    "    x[\"session\"] = session\n",
    "    return x\n",
    "\n",
    "tqdm.pandas()\n",
    "df = df.progress_apply(make_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/brunch/predict/dev.users\") as fp:\n",
    "    dev = [elem[0:-1] for elem in fp]\n",
    "with open(\"../data/brunch/predict/test.users\") as fp:\n",
    "    test = [elem[0:-1] for elem in fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = df[df.id.isin(dev)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_grouped = df_dev.groupby(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "printed = False\n",
    "\n",
    "def get_length(x):\n",
    "    id = x[0]\n",
    "    frame = x[1]\n",
    "    global printed\n",
    "    \n",
    "    session = frame.session\n",
    "    lengths = [len(elem) for elem in session]\n",
    "    return pd.DataFrame({\n",
    "        \"id\": [id],\n",
    "        \"length\": [np.sum(lengths)]\n",
    "    })\n",
    "\n",
    "df_dev_grouped = [elem for elem in df_dev_grouped]\n",
    "sampled = df_dev_grouped[0:100]\n",
    "df_list = []\n",
    "for elem in tqdm(sampled):\n",
    "    df_list.append(get_length(elem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.sort_values(\"length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.id == \"#009bca89575df8ed68a302c1ceaf7da4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [row for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_parallel_process(frame):    \n",
    "    session = frame.session\n",
    "    if len(session) < 2:\n",
    "        return -1\n",
    "    frame[\"session_input\"] = session[0:-1]\n",
    "    frame[\"session_output\"] = session[1:]\n",
    "    \n",
    "    session = session[0:-1]\n",
    "    session_length = len(session)\n",
    "    # generating session mask\n",
    "    session_mask = [1.0] * (session_length - 1)\n",
    "    session_mask = [0.0] + session_mask\n",
    "    # generating user mask\n",
    "    user_mask = [0.0] * (session_length - 1)\n",
    "    user_mask = user_mask + [1.0]\n",
    "    frame[\"session_mask\"] = session_mask\n",
    "    frame[\"user_mask\"] = user_mask\n",
    "    \n",
    "    return frame\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(cores) as p:\n",
    "    df = list(tqdm(p.imap(user_parallel_process, df), total=len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/dictionary.json\") as fp:\n",
    "    dictionary = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "values = []\n",
    "for key, value in dictionary.items():\n",
    "    keys.append(key)\n",
    "    values.append(value)\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"id\" : keys,\n",
    "    \"pos\" : values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/brunch/dataframe_dictionary.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"../data/dictionary.json\") as fp:\n",
    "    dictionary = json.load(fp)\n",
    "dataset = pq.ParquetDataset(\"../data/brunch/train\")\n",
    "table = dataset.read()\n",
    "df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numpy_fill(arr):\n",
    "    '''Solution provided by Divakar.'''\n",
    "    mask = np.isnan(arr)\n",
    "    idx = np.where(~mask,np.arange(mask.shape[1]),0)\n",
    "    np.maximum.accumulate(idx,axis=1, out=idx)\n",
    "    out = arr[np.arange(idx.shape[0])[:,None], idx]\n",
    "    return out\n",
    "\n",
    "def forward_fill(record):\n",
    "    \n",
    "    pos = record[\"pos\"]\n",
    "    session_input = record[\"session_input\"]\n",
    "    session_output = record[\"session_output\"]\n",
    "    \n",
    "    if len(pos) == 0:\n",
    "        record[\"trainable\"] = False\n",
    "        return record\n",
    "    \n",
    "    if len(session_input) == 0 and len(session_output) == 0:\n",
    "        session_input = [float(pos[0])]\n",
    "        session_output = [float(pos[0])]\n",
    "    \n",
    "    input_nans = np.isnan(session_input)\n",
    "    output_nans = np.isnan(session_output)\n",
    "    \n",
    "    if all(input_nans):\n",
    "        record[\"trainable\"] = False\n",
    "        return record\n",
    "    if np.isnan(session_input[0]):\n",
    "        session_input[0] = float(len(dictionary))\n",
    "    session_input = numpy_fill(np.array([session_input]))[0]\n",
    "    record[\"session_input\"] = session_input\n",
    "    \n",
    "    if all(output_nans):\n",
    "        record[\"trainable\"] = False\n",
    "        return record\n",
    "    if np.isnan(session_output[0]):\n",
    "        session_output[0] = session_input[1]\n",
    "    session_output = numpy_fill(np.array([session_output]))[0]\n",
    "    record[\"session_output\"] = session_output\n",
    "    record[\"trainable\"] = True\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3493934/3493934 [1:07:30<00:00, 862.69it/s] \n"
     ]
    }
   ],
   "source": [
    "df = df.progress_apply(forward_fill, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/brunch/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>session</th>\n",
       "      <th>history</th>\n",
       "      <th>idx</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pos</th>\n",
       "      <th>session_input</th>\n",
       "      <th>session_output</th>\n",
       "      <th>session_mask</th>\n",
       "      <th>user_mask</th>\n",
       "      <th>trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>561926</th>\n",
       "      <td>#00104b6ef7bea05a3264ea0ab197fba9</td>\n",
       "      <td>1342</td>\n",
       "      <td>[@wootaiyoung_19, @snobberys_109, @tenbody_902...</td>\n",
       "      <td>[5, 3, 0, 4, 2, 1]</td>\n",
       "      <td>[2018-11-25T22:00:00.000000000, 2018-11-25T22:...</td>\n",
       "      <td>[60128, 355501, 38319, 568640]</td>\n",
       "      <td>[38319.0, 38319.0, 38319.0, 355501.0, 568640.0]</td>\n",
       "      <td>[38319.0, 38319.0, 355501.0, 568640.0, 60128.0]</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  session  \\\n",
       "561926  #00104b6ef7bea05a3264ea0ab197fba9     1342   \n",
       "\n",
       "                                                  history                 idx  \\\n",
       "561926  [@wootaiyoung_19, @snobberys_109, @tenbody_902...  [5, 3, 0, 4, 2, 1]   \n",
       "\n",
       "                                                timestamp  \\\n",
       "561926  [2018-11-25T22:00:00.000000000, 2018-11-25T22:...   \n",
       "\n",
       "                                   pos  \\\n",
       "561926  [60128, 355501, 38319, 568640]   \n",
       "\n",
       "                                          session_input  \\\n",
       "561926  [38319.0, 38319.0, 38319.0, 355501.0, 568640.0]   \n",
       "\n",
       "                                         session_output  \\\n",
       "561926  [38319.0, 38319.0, 355501.0, 568640.0, 60128.0]   \n",
       "\n",
       "                     session_mask                  user_mask  trainable  \n",
       "561926  [0.0, 1.0, 1.0, 1.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]       True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.id == \"#00104b6ef7bea05a3264ea0ab197fba9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_parquet(\"../data/brunch/sample_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"../data/dictionary.json\") as fp:\n",
    "    dictionary = json.load(fp)\n",
    "\n",
    "df = pd.read_parquet(\"../data/brunch/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>session</th>\n",
       "      <th>history</th>\n",
       "      <th>idx</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pos</th>\n",
       "      <th>session_input</th>\n",
       "      <th>session_output</th>\n",
       "      <th>session_mask</th>\n",
       "      <th>user_mask</th>\n",
       "      <th>trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>561926</th>\n",
       "      <td>#00104b6ef7bea05a3264ea0ab197fba9</td>\n",
       "      <td>1342</td>\n",
       "      <td>[@wootaiyoung_19, @snobberys_109, @tenbody_902...</td>\n",
       "      <td>[5, 3, 0, 4, 2, 1]</td>\n",
       "      <td>[2018-11-25T22:00:00.000, 2018-11-25T22:00:00....</td>\n",
       "      <td>[60128, 355501, 38319, 568640]</td>\n",
       "      <td>[38319.0, 38319.0, 38319.0, 355501.0, 568640.0]</td>\n",
       "      <td>[38319.0, 38319.0, 355501.0, 568640.0, 60128.0]</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  session  \\\n",
       "561926  #00104b6ef7bea05a3264ea0ab197fba9     1342   \n",
       "\n",
       "                                                  history                 idx  \\\n",
       "561926  [@wootaiyoung_19, @snobberys_109, @tenbody_902...  [5, 3, 0, 4, 2, 1]   \n",
       "\n",
       "                                                timestamp  \\\n",
       "561926  [2018-11-25T22:00:00.000, 2018-11-25T22:00:00....   \n",
       "\n",
       "                                   pos  \\\n",
       "561926  [60128, 355501, 38319, 568640]   \n",
       "\n",
       "                                          session_input  \\\n",
       "561926  [38319.0, 38319.0, 38319.0, 355501.0, 568640.0]   \n",
       "\n",
       "                                         session_output  \\\n",
       "561926  [38319.0, 38319.0, 355501.0, 568640.0, 60128.0]   \n",
       "\n",
       "                     session_mask                  user_mask  trainable  \n",
       "561926  [0.0, 1.0, 1.0, 1.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]       True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.id == \"#00104b6ef7bea05a3264ea0ab197fba9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainable = df[df.trainable == True]\n",
    "df_trainable = df_trainable.groupby(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 197/301930 [00:06<244:59:40,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 38319  38319 355501 568640  60128 642190 642190 642190 642190 642190\n",
      "  642190 642190 642190 642190 642190 642190 642190 642190 642190 642190\n",
      "  642190 642190 642190 642190 642190 642190 642190 642190 642190 642190]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301930/301930 [05:06<00:00, 986.68it/s] \n"
     ]
    }
   ],
   "source": [
    "input_list = []\n",
    "label_list = []\n",
    "mask_list = []\n",
    "\n",
    "idx = 0\n",
    "max_length = 30\n",
    "dictionary_length = len(dictionary)\n",
    "\n",
    "for idx, (key, frame) in tqdm(enumerate(df_trainable), total=len(df_trainable)):\n",
    "        frame = frame.sort_values(\"session\")\n",
    "    \n",
    "        session_input = np.concatenate(frame.session_input.values, axis=None)\n",
    "        session_output = np.concatenate(frame.session_output.values, axis=None)\n",
    "        session_mask = np.concatenate(frame.session_mask.values, axis=None)\n",
    "        user_mask = np.concatenate(frame.user_mask.values, axis=None)\n",
    "            \n",
    "        message = \"At least one of the dimension doesn't match in the input.\"\n",
    "        assert len(session_input) == len(session_output), message\n",
    "        assert len(session_output) == len(session_mask), message\n",
    "        assert len(session_mask) == len(user_mask), message\n",
    "        \n",
    "        if len(session_input) > 30:\n",
    "            continue\n",
    "            \n",
    "        inputs = [session_input, session_mask, user_mask]\n",
    "        inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, \n",
    "                                                               maxlen=max_length, \n",
    "                                                               padding=\"post\")\n",
    "        label = tf.keras.preprocessing.sequence.pad_sequences([session_output], \n",
    "                                                              maxlen=max_length, \n",
    "                                                              value=np.float64(dictionary_length), \n",
    "                                                              padding=\"post\")\n",
    "\n",
    "        mask = [1.0] * len(session_input)\n",
    "        mask = tf.keras.preprocessing.sequence.pad_sequences([mask],\n",
    "                                                           maxlen=max_length,\n",
    "                                                           value = 0.0,\n",
    "                                                           padding=\"post\")\n",
    "        \n",
    "        input_list.append(inputs)\n",
    "        label_list.append(label)\n",
    "        mask_list.append(mask)\n",
    "        \n",
    "        if key == \"#00104b6ef7bea05a3264ea0ab197fba9\":\n",
    "            print(label)\n",
    "        \n",
    "inputs = np.array(input_list)\n",
    "label = np.array(label_list)\n",
    "mask = np.array(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/brunch/train\", inputs)\n",
    "np.save(\"../data/brunch/label\", label)\n",
    "np.save(\"../data/brunch/mask\", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
