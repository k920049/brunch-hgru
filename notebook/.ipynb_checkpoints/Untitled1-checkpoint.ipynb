{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(\"../data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"length\"] = df[\"session_mask\"].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "df = [elem for elem in df.groupby('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "def concatenate(vectors):\n",
    "    elements = [elem for elem in vectors]\n",
    "    return np.concatenate(elements, axis=None)\n",
    "\n",
    "def append_dataframe(df):\n",
    "    id = df[0]\n",
    "    df = df[1]\n",
    "    \n",
    "    df = df.sort_values(\"timestamp\")\n",
    "    history = concatenate(df[\"history\"].values)\n",
    "    timestamp = concatenate(df[\"timestamp\"].values)\n",
    "    session = concatenate(df[\"session\"].values)\n",
    "    session_mask = concatenate(df[\"session_mask\"].values)\n",
    "    user_mask = concatenate(df[\"user_mask\"].values)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"id\": [id],\n",
    "        \"history\": [history],\n",
    "        \"timestamp\": [timestamp],\n",
    "        \"session\": [session],\n",
    "        \"session_mask\": [session_mask],\n",
    "        \"user_mask\": [user_mask],\n",
    "        \"length\": np.sum(df[\"length\"].values)\n",
    "    })\n",
    "\n",
    "with multiprocessing.Pool(cores) as p:\n",
    "    df = list(tqdm(p.imap(append_dataframe, df), total=len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/masked.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(\"../data/brunch/session.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"../data/dictionary.json\") as fp:\n",
    "    dictionary = json.load(fp)\n",
    "    \n",
    "def make_label(x):\n",
    "    session = x[\"history\"]\n",
    "    session = [dictionary[elem] for elem in session if elem in dictionary]\n",
    "    x[\"session\"] = session\n",
    "    return x\n",
    "\n",
    "tqdm.pandas()\n",
    "df = df.progress_apply(make_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/brunch/predict/dev.users\") as fp:\n",
    "    dev = [elem[0:-1] for elem in fp]\n",
    "with open(\"../data/brunch/predict/test.users\") as fp:\n",
    "    test = [elem[0:-1] for elem in fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = df[df.id.isin(dev)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_grouped = df_dev.groupby(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "printed = False\n",
    "\n",
    "def get_length(x):\n",
    "    id = x[0]\n",
    "    frame = x[1]\n",
    "    global printed\n",
    "    \n",
    "    session = frame.session\n",
    "    lengths = [len(elem) for elem in session]\n",
    "    return pd.DataFrame({\n",
    "        \"id\": [id],\n",
    "        \"length\": [np.sum(lengths)]\n",
    "    })\n",
    "\n",
    "df_dev_grouped = [elem for elem in df_dev_grouped]\n",
    "sampled = df_dev_grouped[0:100]\n",
    "df_list = []\n",
    "for elem in tqdm(sampled):\n",
    "    df_list.append(get_length(elem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.sort_values(\"length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.id == \"#009bca89575df8ed68a302c1ceaf7da4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [row for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_parallel_process(frame):    \n",
    "    session = frame.session\n",
    "    if len(session) < 2:\n",
    "        return -1\n",
    "    frame[\"session_input\"] = session[0:-1]\n",
    "    frame[\"session_output\"] = session[1:]\n",
    "    \n",
    "    session = session[0:-1]\n",
    "    session_length = len(session)\n",
    "    # generating session mask\n",
    "    session_mask = [1.0] * (session_length - 1)\n",
    "    session_mask = [0.0] + session_mask\n",
    "    # generating user mask\n",
    "    user_mask = [0.0] * (session_length - 1)\n",
    "    user_mask = user_mask + [1.0]\n",
    "    frame[\"session_mask\"] = session_mask\n",
    "    frame[\"user_mask\"] = user_mask\n",
    "    \n",
    "    return frame\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(cores) as p:\n",
    "    df = list(tqdm(p.imap(user_parallel_process, df), total=len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/dictionary.json\") as fp:\n",
    "    dictionary = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "values = []\n",
    "for key, value in dictionary.items():\n",
    "    keys.append(key)\n",
    "    values.append(value)\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"id\" : keys,\n",
    "    \"pos\" : values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/brunch/dataframe_dictionary.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "dataset = pq.ParquetDataset(\"../data/brunch/train\")\n",
    "table = dataset.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"id\", \"session\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[\"@seochogirl_18\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numpy_fill(arr):\n",
    "    '''Solution provided by Divakar.'''\n",
    "    mask = np.isnan(arr)\n",
    "    idx = np.where(~mask,np.arange(mask.shape[1]),0)\n",
    "    np.maximum.accumulate(idx,axis=1, out=idx)\n",
    "    out = arr[np.arange(idx.shape[0])[:,None], idx]\n",
    "    return out\n",
    "\n",
    "def forward_fill(record):\n",
    "    \n",
    "    pos =record[\"pos\"]\n",
    "    session_input = record[\"session_input\"]\n",
    "    session_output = record[\"session_output\"]\n",
    "    \n",
    "    if len(pos) == 0:\n",
    "        record[\"trainable\"] = False\n",
    "        return record\n",
    "    \n",
    "    if len(session_input) == 0 and len(session_output) == 0:\n",
    "        session_input = [float(pos[0])]\n",
    "        session_output = [float(pos[0])]\n",
    "    \n",
    "    input_nans = np.isnan(session_input)\n",
    "    output_nans = np.isnan(session_output)\n",
    "    \n",
    "    if all(input_nans):\n",
    "        record[\"trainable\"] = False\n",
    "        return record\n",
    "    if np.isnan(session_input[0]):\n",
    "        session_input[0] = len(dictionary)\n",
    "    record[\"session_input\"] = numpy_fill(np.array([session_input]))[0]\n",
    "    \n",
    "    if all(output_nans):\n",
    "        record[\"trainable\"] = False\n",
    "        return record\n",
    "    if np.isnan(session_output[0]):\n",
    "        session_output[0] = session_input[1]\n",
    "    record[\"session_output\"] = numpy_fill(np.array([session_output]))[0]\n",
    "    record[\"trainable\"] = True\n",
    "    \n",
    "    return record\n",
    "\n",
    "df = df.progress_apply(forward_fill, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../data/brunch/train/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jeasungpark/Repository/hgru4rec/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_parquet(\"../data/brunch/train/train.parquet\")\n",
    "df_trainable = df[df.trainable == True]\n",
    "df_trainable = df_trainable.groupby(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301930/301930 [05:03<00:00, 993.84it/s] \n"
     ]
    }
   ],
   "source": [
    "input_list = []\n",
    "label_list = []\n",
    "mask_list = []\n",
    "\n",
    "idx = 0\n",
    "max_length = 30\n",
    "dictionary_length = len(dictionary)\n",
    "\n",
    "for idx, (key, frame) in tqdm(enumerate(df_trainable), total=len(df_trainable)):\n",
    "        frame = frame.sort_values(\"session\")\n",
    "    \n",
    "        session_input = np.concatenate(frame.session_input.values, axis=None)\n",
    "        session_output = np.concatenate(frame.session_output.values, axis=None)\n",
    "        session_mask = np.concatenate(frame.session_mask.values, axis=None)\n",
    "        user_mask = np.concatenate(frame.user_mask.values, axis=None)\n",
    "            \n",
    "        message = \"At least one of the dimension doesn't match in the input.\"\n",
    "        assert len(session_input) == len(session_output), message\n",
    "        assert len(session_output) == len(session_mask), message\n",
    "        assert len(session_mask) == len(user_mask), message\n",
    "        \n",
    "        if len(session_input) > 30:\n",
    "            continue\n",
    "\n",
    "        inputs = [session_input, session_mask, user_mask]\n",
    "        inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, \n",
    "                                                               maxlen=max_length, \n",
    "                                                               padding=\"post\")\n",
    "        label = tf.keras.preprocessing.sequence.pad_sequences([session_output], \n",
    "                                                              maxlen=max_length, \n",
    "                                                              value=float(dictionary_length), \n",
    "                                                              padding=\"post\")\n",
    "        mask = [1.0] * len(session_input)\n",
    "        mask = tf.keras.preprocessing.sequence.pad_sequences([mask],\n",
    "                                                           maxlen=max_length,\n",
    "                                                           value = 0.0,\n",
    "                                                           padding=\"post\")\n",
    "        \n",
    "        input_list.append(inputs)\n",
    "        label_list.append(label)\n",
    "        mask_list.append(mask)\n",
    "        \n",
    "inputs = np.array(input_list)\n",
    "label = np.array(label_list)\n",
    "mask = np.array(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../data/dictionary.json\") as fp:\n",
    "    dictionary = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222408, 1, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222408, 3, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222408, 1, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = np.max(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642190"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.where(label == (dictionary_length - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([165548]), array([0]), array([4]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
